LAB 1 (SETUP): 
1. Identify and explain the additional functionalities introduced in Code #2. How do these changes transform the program from a simple image capture to a movement detection system?
-  Real-Time Video Processing: Code #2 captures video frames continuously in a loop and processes them in real-time to detect movement. This is a fundamental shift from Code #1, which captures a single static image.
-  Movement Detection: It uses frame differencing, image processing (converting to grayscale, blurring, thresholding, dilating), and contour detection to identify and highlight areas of movement.


2. Several new OpenCV functions are used (like cv2.absdiff, cv2.cvtColor, cv2.GaussianBlur, cv2.threshold, cv2.dilate, and cv2.findContours). Research each of these functions and understand their role in processing the video frames for movement detection.
-  cv2.absdiff: Calculates the absolute difference between two frames. This is used to detect changes between consecutive frames, highlighting areas of motion.
-  cv2.cvtColor: Converts an image from one color space to another. In this case, it's used to convert the frame from BGR to grayscale, simplifying the processing by reducing the image to a single channel.
-  cv2.GaussianBlur: Applies Gaussian blur to an image. This step helps to reduce image noise and detail, making the thresholding step more effective.
-  cv2.threshold: Applies a fixed-level threshold to each pixel in an image. Pixels with a value above the threshold are set to one value (white), and others to another (black), creating a binary image where the white areas represent potential movement.
-  cv2.dilate: Increases the white region in the image, which is useful for joining broken parts of an object in the binary image.
-  cv2.findContours: Detects contours in a binary image. Contours are used to outline the white areas (detected movements) in the processed frames.


3. The program uses specific conditions (such as contour area) to decide when to draw rectangles and indicate movement. Experiment with these parameters to see how they affect the accuracy and sensitivity of movement detection.
- The condition checking the contour area (cv2.contourArea(contour) < 900) serves as a filter to ignore minor movements that might be caused by noise or small, irrelevant movements. Adjusting this threshold can significantly affect the system's sensitivity to motion. Increasing the value would make the system less sensitive (detecting only larger movements), while decreasing it would make it more sensitive to even slight movements.


4. Loop Mechanics and Video Processing: Analyze the role of the while loop in the 2nd Code for continuous video capture and processing. How does this looping mechanism differ from the single capture approach in the 1st Code, especially in terms of real-time processing and movement detection?
-  While Loop: Code #2 utilizes a while True: loop for continuous video capture and processing. This allows the program to continuously read frames from the webcam, process them for motion detection, and update the display in real-time. This approach is fundamentally different from Code #1, which captures and processes just a single image. The continuous loop enables real-time processing and movement detection.
-  Frame Processing: Each iteration of the loop processes a pair of consecutive frames to detect motion, updates the display, and then shifts the frame references to prepare for the next iteration. This ensures ongoing detection and visualization of movement.


5. Consider aspects like improving the accuracy of movement detection, optimizing performance, or adding new features (like recording video when movement is detected).
-  Accuracy: Accuracy can be improved by fine-tuning the processing parameters, like the Gaussian blur kernel size, threshold values, and contour area threshold. Adaptive thresholding or background subtraction methods could also be explored for better results in diverse lighting conditions.
-  Performance Optimization: Performance can be optimized by processing frames at a lower resolution, applying more efficient algorithms for motion detection, or using hardware acceleration options available in OpenCV.
-  New Features: To enhance the program, features like recording video upon detecting movement could be added. This could involve checking for significant motion over a set of frames and, upon detection, initiating video recording until the motion ceases.


LAB 2 (MQTT): 
Listener 1883 - 1883 is the default port number for MQTT ; IF DONT PUT THEN THE CODE WILL ONLY WORK AS A LOCAL HOST AND WILL NOT WORK IF U GIVE A SPECIFIC IP. IF CLIENTS - SUBSCRIBER AND PUBLISHER ARE USING DIFFERENT PCs THAN THE BROKER THEN IT WILL NOT WORK 

Allow_anonymous true - ensures that u will allow clients that are not registered otherwise the broker might reject u ( clients can connect without providing a username and password) 

Source myenv/bin/activate - activating virtual environment - if dont activate this, then pip install paho-mqtt command will not work 


LAB 3 (SOUND): 
1. What do i need to change for the buffer to capture fewer samples? 
Original: BUFFER = 1024 * 16  # samples per frame
Capture fewer: BUFFER = 1024 * 8  # Halves the number of samples per frame
CONSIDERATIONS: 
-  Audio Quality and Resolution: A smaller buffer size means less data is captured in each frame, which can affect both the temporal resolution of the waveform and the frequency resolution of the FFT spectrum.
-  Processing Load: Reducing the buffer size can also increase the processing load since the loop will iterate more frequently, executing FFT and updating the plot more often.
-  Latency: A smaller buffer can reduce latency in real-time processing applications, making the system more responsive.


2. Key difference between pyaudio and sounddevice 
-  Audio Capture Library: Unlike the PyAudio example, this script uses the sounddevice library for audio capture, showcasing an alternative method for real-time audio input.
-  Blocking Recording: The recording is done in a blocking manner, meaning the script waits for each audio chunk to be fully recorded before proceeding. This simplifies the recording loop but could affect real-time responsiveness in more complex applications.
-  FFT Execution Time Measurement: This script specifically measures and reports the execution time of the FFT operation, providing insights into the performance of real-time audio processing tasks.


3. How do i change the ylim to see more amplitude values? 
OG: ax1.set_ylim(-5000, 5000) 
more: ax1.set_ylim(-10000, 10000)
CONSIDERATIONS: 
-  Signal Clipping: Itâ€™s important to ensure that the ylim values are set wide enough to avoid clipping the waveform display. Clipping occurs when part of the waveform exceeds the plot's Y-axis limits, causing the signal's peaks to be "cut off" visually.
-  Visualization Clarity: While it might be tempting to set very wide limits to catch all possible amplitude values, doing so might make smaller variations in the signal harder to see. Finding a balance based on the expected amplitude range of your audio signals is key.


4. how do i change the filter to lower frequency? 
OG: sos = design_filter(19400, 19600, RATE, 3) #this is like the upper limit of a human hearing, adult hearing is from 31hz to 19000hz 
low: sos = design_filter(300, 800, RATE, 3)
Rate: Ensure that the sampling rate is appropriate for the frequencies you wish to filter. According to the Nyquist theorem, the sampling rate should be at least twice the highest frequency you wish to capture. The current sampling rate of 44,100 Hz (CD quality) is sufficient for most audio applications, including lower frequencies.


5. what happens if cap.release() isnt written? 
The camera might not be properly released back to the operating system. This could lead to several issues, including:
-  Resource Locking: The camera may remain locked or in use by your application, preventing other applications (or instances of the same application) from accessing the camera. This is because cap.release() tells OpenCV to close the video capturing device correctly, releasing the hardware resources.
-  Unexpected Behavior in Subsequent Runs: If the camera is not properly released, subsequent attempts to access the camera might fail or result in undefined behavior. For example, trying to open the camera again in another part of your code or in a different application might not work until the original application is completely terminated or the system is restarted.
-  Increased Power Consumption: Depending on the camera and driver implementation, failing to release the camera properly might keep it powered on, leading to unnecessary power consumption. This can be particularly problematic for battery-powered devices.
-  System Instability: Although less common, improperly managed hardware resources can sometimes lead to system instability or crashes, especially if the camera is repeatedly accessed without being released.
-  Delayed Release by the Operating System: In some cases, the operating system may eventually force the release of the camera resource once the Python process is terminated. However, this is not guaranteed and can be inconsistent across different operating systems and camera drivers.


6. what would happen if cv2.destroyAllWindows() wasnt in the code? 
-  Windows Remain Open: The windows opened by your application for displaying images or video might stay open even after the main execution of your code has finished. You might be able to manually close them by clicking the close button on the window, but in some environments or situations, the windows might become unresponsive, failing to close properly.
-  Resource Consumption: Open windows consume system resources. While not typically significant, if many windows are left open or if the program is run multiple times without closing previous windows, it could lead to unnecessary resource utilization.
-  Cluttered Workspace: From a user experience perspective, leaving windows open can clutter the screen, especially if your application is supposed to run multiple times or is part of a larger workflow. It can become cumbersome for users to manually close these windows every time.
-  Potential Memory Leaks: Depending on the version of OpenCV and the specific environment (operating system and Python version), not properly disposing of windows could lead to memory leaks. While modern operating systems are quite good at reclaiming resources once a process exits, explicitly closing your windows is a good practice to ensure that resources are cleaned up promptly and reliably.
-  Delayed System Cleanup: In some cases, the operating system will clean up the resources used by your application once it terminates. However, relying on the operating system for cleanup is not a best practice. Explicitly managing resources within your code ensures that your application behaves predictively and cleanly, regardless of the operating system's behavior.


LAB 4 (IMAGE): 
1. how should i resize the frame for faster processing?
Common lower resolutions include:
640x480 (VGA): Often sufficient for basic object detection tasks.
320x240 (QVGA): Can be used for less detailed applications.
160x120: For very fast processing with minimal detail requirements.
# Resize the frame to half the original width and height while maintaining the aspect ratio
frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)





